{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://news.google.com/read/CBMiwAFBVV95cUxNRHBJY3Yza190anEyY1RWQnBEdk1XUFQtWFRSSXB2Ml9hVnM3dEs0ZkZJNWgwRGNmWDVyLWhMNFJZOFpud04xNm1iN0FWU1lqMThYcGNKUlBJQXNaOEszMXlZek9SZ2NCU3Vac093TVdyMnZybHhJWDFxbmhFVFc4bU9tTkZKcmlsOFB5QWZLNUNoNzhYX09mQ0R6U0VzOEtRbFZFdHpnU1I1amo3WlRWVHpLak8zRWkzcTIwR0J0aTI?hl=en-IN&gl=IN&ceid=IN%3Aen'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Triveni TurbinesTEST_google_news.csv\")\n",
    "df[\"link\"].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# import time\n",
    "\n",
    "# def redirect_the_link(google_url):\n",
    "#     chrome_options = Options()\n",
    "#     chrome_options.add_argument(\"--disable-gpu\")\n",
    "#     chrome_options.add_argument(\"--no-sandbox\")\n",
    "#     chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")  \n",
    "#     chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "#     chrome_options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "#     # Add a real User-Agent string\n",
    "#     chrome_options.add_argument(\n",
    "#         \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
    "#     )\n",
    "\n",
    "#     service = Service()\n",
    "#     driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "#     # Hide Selenium WebDriver\n",
    "#     driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "\n",
    "#     driver.get(google_url)\n",
    "#     time.sleep(5)  # Increase sleep time to avoid rapid requests\n",
    "\n",
    "#     final_url = driver.current_url\n",
    "#     driver.quit()\n",
    "#     return final_url\n",
    "\n",
    "\n",
    "import undetected_chromedriver as uc\n",
    "import time\n",
    "\n",
    "def redirect_the_link(google_url):\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "    # Set user-agent\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\")\n",
    "\n",
    "    driver = uc.Chrome(options=options)\n",
    "\n",
    "    driver.get(google_url)\n",
    "    time.sleep(5) \n",
    "    final_url = driver.current_url\n",
    "    driver.quit()\n",
    "    return final_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redirected to: https://www.google.com/sorry/index?continue=https://news.google.com/read/CBMiwAFBVV95cUxNRHBJY3Yza190anEyY1RWQnBEdk1XUFQtWFRSSXB2Ml9hVnM3dEs0ZkZJNWgwRGNmWDVyLWhMNFJZOFpud04xNm1iN0FWU1lqMThYcGNKUlBJQXNaOEszMXlZek9SZ2NCU3Vac093TVdyMnZybHhJWDFxbmhFVFc4bU9tTkZKcmlsOFB5QWZLNUNoNzhYX09mQ0R6U0VzOEtRbFZFdHpnU1I1amo3WlRWVHpLak8zRWkzcTIwR0J0aTI%3Fhl%3Den-IN%26gl%3DIN%26ceid%3DIN%253Aen&hl=en-IN&q=EgTS1F0uGLOn9L4GIjAqraWdh_B4KVYEFDrAVV5jcRy0XdX6HpSos2tJbl1j_I2z4CR2Z_budHi3ioWd6qwyAnJSWgFD\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m f_url_ls \u001b[39m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m df[\u001b[39m\"\u001b[39m\u001b[39mlink\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m     final_link \u001b[39m=\u001b[39m redirect_the_link(i)\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRedirected to:\u001b[39m\u001b[39m\"\u001b[39m, final_link)\n\u001b[1;32m      5\u001b[0m     f_url_ls\u001b[39m.\u001b[39mappend(final_link)\n",
      "Cell \u001b[0;32mIn[23], line 26\u001b[0m, in \u001b[0;36mredirect_the_link\u001b[0;34m(google_url)\u001b[0m\n\u001b[1;32m     23\u001b[0m driver\u001b[39m.\u001b[39mexecute_script(\u001b[39m\"\u001b[39m\u001b[39mObject.defineProperty(navigator, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mwebdriver\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39m\u001b[39mget: () => undefined})\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m driver\u001b[39m.\u001b[39mget(google_url)\n\u001b[0;32m---> 26\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m5\u001b[39;49m)  \u001b[39m# Increase sleep time to avoid rapid requests\u001b[39;00m\n\u001b[1;32m     28\u001b[0m final_url \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mcurrent_url\n\u001b[1;32m     29\u001b[0m driver\u001b[39m.\u001b[39mquit()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f_url_ls = []\n",
    "for i in df[\"link\"]:\n",
    "    final_link = redirect_the_link(i)\n",
    "    print(\"Redirected to:\", final_link)\n",
    "    f_url_ls.append(final_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.87 seconds\n",
      "\n",
      "Extracted Content:\n",
      "Title: Tesla Stock Surges Tuesday After Major Sell-Off\n",
      "Date: By ANDREW KESSEL\n"
     ]
    }
   ],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# import time\n",
    "\n",
    "# # Global driver setup for speed (initialize once)\n",
    "# chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "# chrome_options.add_argument(\"--disable-gpu\")\n",
    "# chrome_options.add_argument(\"--no-sandbox\")\n",
    "# chrome_options.add_argument(\"--disable-extensions\")\n",
    "# chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Reduce memory\n",
    "# chrome_options.add_argument(\"--blink-settings=imagesEnabled=false\")  # Disable images\n",
    "# chrome_options.add_argument(\n",
    "#     \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
    "# )\n",
    "# service = Service()\n",
    "# driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# def scrape_title_and_date(url):\n",
    "#     \"\"\"Fast Selenium scrape with comprehensive date extraction.\"\"\"\n",
    "#     try:\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         # Load page\n",
    "#         driver.get(url)\n",
    "        \n",
    "#         # Wait for title (max 3 seconds)\n",
    "#         WebDriverWait(driver, 3).until(\n",
    "#             EC.presence_of_element_located((By.TAG_NAME, \"title\"))\n",
    "#         )\n",
    "        \n",
    "#         # Extract title\n",
    "#         title = driver.title.strip()\n",
    "\n",
    "#         # Comprehensive date extraction (from your previous code)\n",
    "#         date = None\n",
    "\n",
    "#         # Method 1: Meta tags\n",
    "#         meta_date = driver.find_elements(By.XPATH, \"//meta[@property='article:published_time' or @name='pubdate' or @name='date']\")\n",
    "#         if meta_date:\n",
    "#             date = meta_date[0].get_attribute(\"content\")\n",
    "        \n",
    "#         # Method 2: <time> tags with datetime or text\n",
    "#         if not date:\n",
    "#             time_tags = driver.find_elements(By.TAG_NAME, \"time\")\n",
    "#             for tag in time_tags:\n",
    "#                 date = tag.get_attribute(\"datetime\") or tag.text.strip()\n",
    "#                 if date:\n",
    "#                     break\n",
    "\n",
    "#         # Method 3: Common class names or IDs\n",
    "#         if not date:\n",
    "#             date_elements = driver.find_elements(By.XPATH, \"//*[contains(@class, 'date') or contains(@class, 'time') or contains(@class, 'published') or @id='date']\")\n",
    "#             if date_elements:\n",
    "#                 date = date_elements[0].text.strip() or date_elements[0].get_attribute(\"datetime\")\n",
    "\n",
    "#         # Method 4: Text patterns near \"Published\" or \"Updated\"\n",
    "#         if not date:\n",
    "#             potential_dates = driver.find_elements(By.XPATH, \"//*[contains(text(), 'Published') or contains(text(), 'Updated') or contains(text(), 'Date')]\")\n",
    "#             if potential_dates:\n",
    "#                 date = potential_dates[0].text.strip()\n",
    "\n",
    "#         date = date if date else \"Date not found\"\n",
    "\n",
    "#         elapsed_time = time.time() - start_time\n",
    "#         print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "#         return {\"title\": title, \"date\": date}\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error scraping {url}: {e}\")\n",
    "#         return {\"title\": None, \"date\": None}\n",
    "    \n",
    "    \n",
    "# # Test with Moneycontrol URL\n",
    "# result = scrape_title_and_date(final_url)\n",
    "# print(\"\\nExtracted Content:\")\n",
    "# print(f\"Title: {result['title']}\")\n",
    "# print(f\"Date: {result['date']}\")\n",
    "\n",
    "# # Uncomment to close driver when done with all scraping\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Initialize a new ChromeDriver instance.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-extensions\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "    chrome_options.add_argument(\n",
    "        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "    service = Service()\n",
    "    return webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "def is_date_like(text):\n",
    "    \"\"\"Basic validation to check if text resembles a date.\"\"\"\n",
    "    if not text:\n",
    "        return False\n",
    "    date_patterns = [\n",
    "        r\"\\d{4}-\\d{2}-\\d{2}\",  # YYYY-MM-DD\n",
    "        r\"\\d{1,2}\\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+\\d{4}\",  # DD Month YYYY\n",
    "        r\"\\d{1,2}/\\d{1,2}/\\d{2,4}\",  # MM/DD/YYYY or DD/MM/YYYY\n",
    "    ]\n",
    "    return any(re.search(pattern, text, re.IGNORECASE) for pattern in date_patterns) or any(c.isdigit() for c in text)\n",
    "\n",
    "def scrape_title_and_date(url):\n",
    "    \"\"\"Fast Selenium scrape with comprehensive date extraction.\"\"\"\n",
    "    driver = None\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Initialize driver\n",
    "        driver = setup_driver()\n",
    "        \n",
    "        # Load page\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for title (max 3 seconds)\n",
    "        WebDriverWait(driver, 3).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"title\"))\n",
    "        )\n",
    "        \n",
    "        # Extract title\n",
    "        title = driver.title.strip()\n",
    "        print(f\"Scraped title: {title}\")\n",
    "\n",
    "        # Comprehensive date extraction\n",
    "        date = None\n",
    "        source = None\n",
    "\n",
    "        # Method 1: Meta tags (most reliable)\n",
    "        meta_date = driver.find_elements(By.XPATH, \"//meta[@property='article:published_time' or @name='pubdate' or @name='date']\")\n",
    "        if meta_date:\n",
    "            date = meta_date[0].get_attribute(\"content\")\n",
    "            source = \"Meta tag\"\n",
    "            if date and not is_date_like(date):\n",
    "                date = None\n",
    "\n",
    "        # Method 2: <time> tags with datetime or text\n",
    "        if not date:\n",
    "            time_tags = driver.find_elements(By.TAG_NAME, \"time\")\n",
    "            for tag in time_tags:\n",
    "                date = tag.get_attribute(\"datetime\") or tag.text.strip()\n",
    "                if date and is_date_like(date):\n",
    "                    source = \"<time> tag\"\n",
    "                    break\n",
    "                date = None\n",
    "\n",
    "        # Method 3: Common class names or IDs\n",
    "        if not date:\n",
    "            date_elements = driver.find_elements(By.XPATH, \"//*[contains(@class, 'date') or contains(@class, 'time') or contains(@class, 'published') or @id='date']\")\n",
    "            for elem in date_elements:\n",
    "                candidate = elem.text.strip() or elem.get_attribute(\"datetime\")\n",
    "                if candidate and is_date_like(candidate):\n",
    "                    date = candidate\n",
    "                    source = \"Class/ID\"\n",
    "                    break\n",
    "            else:\n",
    "                date = None\n",
    "\n",
    "        # Method 4: Text patterns near \"Published\" or \"Updated\"\n",
    "        if not date:\n",
    "            potential_dates = driver.find_elements(By.XPATH, \"//*[contains(text(), 'Published') or contains(text(), 'Updated') or contains(text(), 'Date')]/following-sibling::*[1] | //*[contains(text(), 'Published') or contains(text(), 'Updated') or contains(text(), 'Date')]\")\n",
    "            for elem in potential_dates:\n",
    "                candidate = elem.text.strip()\n",
    "                if candidate and is_date_like(candidate):\n",
    "                    date = candidate\n",
    "                    source = \"Text pattern\"\n",
    "                    break\n",
    "            else:\n",
    "                date = None\n",
    "\n",
    "        date = date if date else \"Date not found\"\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
    "        print(f\"Date extracted: {date} (Source: {source or 'None'})\")\n",
    "        return {\"title\": title, \"date\": date}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return {\"title\": None, \"date\": None}\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
